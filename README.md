# Vision Mamba Robustness Against Adversarial Attacks
## Research Artifact Package â€” Indonesian Traffic Sign Recognition

[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0%2B-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

This repository contains the **research artifact** for a Design Science Research Methodology (DSRM) study on improving and evaluating the robustness of **Vision Mamba** against adversarial attacks in Indonesian Traffic Sign Recognition (TSR).

---

## ğŸ“‹ Citation & Identity

| Field | Value |
|-------|-------|
| **Thesis Title** | Peningkatan Robustness Vision Mamba Terhadap Serangan Adversarial |
| **English Title** | Enhancing the Robustness of Vision Mamba Against Adversarial Attacks |
| **Author** | Marthen Amelius Solang |
| **NIM** | 23523305 |
| **Program** | Master's Program in Informatics |
| **Institution** | Institut Teknologi Bandung (ITB) |
| **Date** | December 2025 |

---

## ğŸ¯ Research Overview

### Problem Statement
Vision Mamba, while efficient for visual representation learning, is highly vulnerable to adversarial attacks. This research evaluates and improves the robustness of Vision Mamba for safety-critical traffic sign recognition.

### Research Objectives
1. Evaluate baseline robustness of Vision Mamba against AutoAttack and Adaptive Attack
2. Implement and compare five defense methods for robustness enhancement
3. Determine the most effective defense strategy for Indonesian TSR applications

### Key Findings
- **Adversarial Training** is the most effective defense method
- Gradient Masking and Defensive Distillation exhibit "false robustness" that collapses under adaptive attacks
- Randomized Smoothing and Certified Robustness provide additional stability layers

---

## ğŸ”„ Research Pipeline Flowchart

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           RESEARCH PIPELINE OVERVIEW                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: DATA PREPARATION & BASELINE TRAINING                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚   Dataset    â”‚â”€â”€â”€â–¶â”‚  Preprocessing   â”‚â”€â”€â”€â–¶â”‚   Vision Mamba      â”‚               â”‚
â”‚   â”‚  (21 classes)â”‚    â”‚  â€¢ Resize 224Ã—224â”‚    â”‚   Baseline Training â”‚               â”‚
â”‚   â”‚  Train/Val/  â”‚    â”‚  â€¢ Normalize     â”‚    â”‚   â€¢ dim=192         â”‚               â”‚
â”‚   â”‚    Test      â”‚    â”‚  â€¢ Patch (32Ã—32) â”‚    â”‚   â€¢ depth=6         â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â€¢ dropout=0.20    â”‚               â”‚
â”‚                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                          â”‚                          â”‚
â”‚                                                          â–¼                          â”‚
â”‚                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                                               â”‚  Baseline Model     â”‚               â”‚
â”‚                                               â”‚  (.pth checkpoint)  â”‚               â”‚
â”‚                                               â”‚  + config.json      â”‚               â”‚
â”‚                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: BASELINE ATTACK EVALUATION                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚   Baseline Model    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚         ATTACK EVALUATION           â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚                                     â”‚           â”‚
â”‚                                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚           â”‚
â”‚                                   â”‚  â”‚ AutoAttack  â”‚  â”‚  Adaptive   â”‚   â”‚           â”‚
â”‚                                   â”‚  â”‚ â€¢ APGD-CE   â”‚  â”‚   Attack    â”‚   â”‚           â”‚
â”‚                                   â”‚  â”‚ â€¢ APGD-DLR  â”‚  â”‚ â€¢ EOT       â”‚   â”‚           â”‚
â”‚                                   â”‚  â”‚ â€¢ FAB-T     â”‚  â”‚ â€¢ BPDA      â”‚   â”‚           â”‚
â”‚                                   â”‚  â”‚ â€¢ Square    â”‚  â”‚ â€¢ Multi-    â”‚   â”‚           â”‚
â”‚                                   â”‚  â”‚             â”‚  â”‚   restart   â”‚   â”‚           â”‚
â”‚                                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚           â”‚
â”‚                                   â”‚                                     â”‚           â”‚
â”‚                                   â”‚  Îµ âˆˆ {0.5, 1, 2, 3, 4, 5, 6, 7, 8} â”‚           â”‚
â”‚                                   â”‚         /255 (Lâˆ norm)              â”‚           â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                    â”‚                                â”‚
â”‚                                                    â–¼                                â”‚
â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚                                   â”‚   Baseline Vulnerability Report    â”‚           â”‚
â”‚                                   â”‚   â€¢ Clean Accuracy                 â”‚           â”‚
â”‚                                   â”‚   â€¢ Robust Accuracy per Îµ          â”‚           â”‚
â”‚                                   â”‚   â€¢ Attack Success Rate            â”‚           â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: ROBUSTNESS ENHANCEMENT (5 DEFENSE METHODS)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚                     DEFENSE METHODS TRAINING                             â”‚       â”‚
â”‚   â”‚                                                                          â”‚       â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚       â”‚
â”‚   â”‚  â”‚  Randomized  â”‚ â”‚   Gradient   â”‚ â”‚  Certified   â”‚ â”‚  Adversarial â”‚    â”‚       â”‚
â”‚   â”‚  â”‚  Smoothing   â”‚ â”‚   Masking    â”‚ â”‚   Robust     â”‚ â”‚   Training   â”‚    â”‚       â”‚
â”‚   â”‚  â”‚              â”‚ â”‚              â”‚ â”‚    Model     â”‚ â”‚    (PGD)     â”‚    â”‚       â”‚
â”‚   â”‚  â”‚ Ïƒ = 0.25     â”‚ â”‚ Gradient     â”‚ â”‚              â”‚ â”‚              â”‚    â”‚       â”‚
â”‚   â”‚  â”‚ Gaussian     â”‚ â”‚ obfuscation  â”‚ â”‚ RS + formal  â”‚ â”‚ Îµ-train      â”‚    â”‚       â”‚
â”‚   â”‚  â”‚ noise        â”‚ â”‚              â”‚ â”‚ certificationâ”‚ â”‚ = 8/255      â”‚    â”‚       â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚       â”‚
â”‚   â”‚                                                                          â”‚       â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚       â”‚
â”‚   â”‚  â”‚                    Defensive Distillation                        â”‚   â”‚       â”‚
â”‚   â”‚  â”‚           Teacher-Student with soft labels (T > 1)               â”‚   â”‚       â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                           â”‚                                         â”‚
â”‚                                           â–¼                                         â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                            â”‚    5 Robust Model Variants   â”‚                         â”‚
â”‚                            â”‚    (.pth checkpoints)        â”‚                         â”‚
â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 4: ROBUST MODEL EVALUATION                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚                    FOR EACH DEFENSE METHOD:                              â”‚       â”‚
â”‚   â”‚                                                                          â”‚       â”‚
â”‚   â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚       â”‚
â”‚   â”‚    â”‚   Robust   â”‚â”€â”€â”€â–¶â”‚   AutoAttack   â”‚â”€â”€â”€â–¶â”‚  Robust Accuracy   â”‚       â”‚       â”‚
â”‚   â”‚    â”‚   Model    â”‚    â”‚   Evaluation   â”‚    â”‚  vs Baseline       â”‚       â”‚       â”‚
â”‚   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚       â”‚
â”‚   â”‚                              â”‚                                           â”‚       â”‚
â”‚   â”‚                              â–¼                                           â”‚       â”‚
â”‚   â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚       â”‚
â”‚   â”‚                      â”‚   Adaptive     â”‚â”€â”€â”€â–¶â”‚  True Robustness   â”‚       â”‚       â”‚
â”‚   â”‚                      â”‚    Attack      â”‚    â”‚  Verification      â”‚       â”‚       â”‚
â”‚   â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                           â”‚                                         â”‚
â”‚                                           â–¼                                         â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                  â”‚            COMPARATIVE ANALYSIS               â”‚                   â”‚
â”‚                  â”‚  â€¢ Clean Accuracy comparison                  â”‚                   â”‚
â”‚                  â”‚  â€¢ Robust Accuracy per method                 â”‚                   â”‚
â”‚                  â”‚  â€¢ Attack Success Rate analysis               â”‚                   â”‚
â”‚                  â”‚  â€¢ False robustness detection                 â”‚                   â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 5: RESULTS & ARTIFACTS                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚   â”‚   CSV Reports   â”‚  â”‚  Visualization  â”‚  â”‚  Model Files    â”‚                     â”‚
â”‚   â”‚   per attack    â”‚  â”‚   (PNG plots)   â”‚  â”‚  (.pth)         â”‚                     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                                      â”‚
â”‚   Final Recommendation: Adversarial Training as primary defense,                     â”‚
â”‚   Randomized Smoothing + Certified Robust as supplementary layers                    â”‚
â”‚                                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Repository Structure

```
vision-mamba-robustness/
â”‚
â”œâ”€â”€ README.md                              # This file
â”œâ”€â”€ requirements.txt                       # Python dependencies
â”‚
â”œâ”€â”€ src/                                   # Source code
â”‚   â”œâ”€â”€ training/                          # Training scripts
â”‚   â”‚   â”œâ”€â”€ baseline_training.py           # Baseline Vision Mamba training
â”‚   â”‚   â”œâ”€â”€ adversarial_training.py        # Adversarial Training (PGD-based)
â”‚   â”‚   â”œâ”€â”€ randomized_smoothing.py        # Randomized Smoothing fine-tuning
â”‚   â”‚   â”œâ”€â”€ certified_robust.py            # Certified Robustness training
â”‚   â”‚   â”œâ”€â”€ defensive_distillation.py      # Teacher-Student distillation
â”‚   â”‚   â””â”€â”€ gradient_masking.py            # Gradient Masking wrapper
â”‚   â”‚
â”‚   â””â”€â”€ evaluation/                        # Attack evaluation scripts
â”‚       â”œâ”€â”€ Autoattack_On_BaseModel.py     # AutoAttack on baseline model
â”‚       â”œâ”€â”€ Adapative_attack_on_base_Model.py  # Adaptive Attack on baseline
â”‚       â””â”€â”€ ... (see Evaluation Scripts section)
â”‚
â”œâ”€â”€ models/                                # Model checkpoints (.pth files)
â”‚   â”œâ”€â”€ baseline/
â”‚   â”‚   â”œâ”€â”€ best_vim_rambu_small.pth       # Baseline model checkpoint
â”‚   â”‚   â”œâ”€â”€ config.json                    # Architecture configuration
â”‚   â”‚   â””â”€â”€ class_mapping.json             # Class index mapping
â”‚   â”‚
â”‚   â”œâ”€â”€ adversarial_training/
â”‚   â”‚   â””â”€â”€ best_robust_model.pth
â”‚   â”‚
â”‚   â”œâ”€â”€ randomized_smoothing/
â”‚   â”‚   â””â”€â”€ best_smoothed_model.pth
â”‚   â”‚
â”‚   â”œâ”€â”€ certified_robust/
â”‚   â”‚   â””â”€â”€ best_certified_model.pth
â”‚   â”‚
â”‚   â”œâ”€â”€ defensive_distillation/
â”‚   â”‚   â””â”€â”€ student_model.pth
â”‚   â”‚
â”‚   â””â”€â”€ gradient_masking/
â”‚       â””â”€â”€ masked_model.pth
â”‚
â”œâ”€â”€ data/                                  # Dataset (not included, see Dataset section)
â”‚   â””â”€â”€ dataset_rambu_lalu_lintas/
â”‚       â”œâ”€â”€ train/
â”‚       â”œâ”€â”€ valid/
â”‚       â””â”€â”€ test/
â”‚
â””â”€â”€ results/                               # Experimental outputs
    â”œâ”€â”€ autoattack/
    â”‚   â””â”€â”€ *.csv, *.png
    â””â”€â”€ adaptive_attack/
        â””â”€â”€ *.csv, *.png
```

---

## ğŸ“œ Evaluation Scripts Overview

### AutoAttack Evaluation Scripts

| Script | Target Model | Description |
|--------|--------------|-------------|
| `Autoattack_On_BaseModel.py` | Baseline | Evaluates baseline Vision Mamba against AutoAttack (Lâˆ) |
| `Attack_on_AdversarialTrain.py` | Adversarial Training | AutoAttack on adversarially trained model |
| `AutoAttack_On_Randomized_Smoothing.py` | Randomized Smoothing | AutoAttack on smoothed model |
| `Attack_On_CertifiedAccuracy.py` | Certified Robust | AutoAttack on certified robust model |
| `AutoAttack_on_DevensiveDestilation.py` | Defensive Distillation | AutoAttack on distilled model |
| `Attack_On_Gradient_Masking_AutoAttack.py` | Gradient Masking | AutoAttack on gradient-masked model |

### Adaptive Attack Evaluation Scripts

| Script | Target Model | Description |
|--------|--------------|-------------|
| `Adapative_attack_on_base_Model.py` | Baseline | TRUE Adaptive PGD attack on baseline |
| `Attack_Model_on_Adversarial_Training.py` | Adversarial Training | Adaptive attack path resolver + evaluation |
| `Attack_on_Randomized_smothing.py` | Randomized Smoothing | Adaptive attack with EOT for stochastic defense |
| `Attack_on_Gradiend_masking.py` | Gradient Masking | Adaptive attack with BPDA for gradient obfuscation |
| `Adaptive_attack_on_Devensive_Destilation.py` | Defensive Distillation | Adaptive attack on distilled model |

---

## âš™ï¸ Attack Configuration

### AutoAttack Settings
```python
ATTACK_TYPE = "standard"  # Standard AutoAttack suite
ATTACKS = ["apgd-ce", "apgd-dlr", "fab-t", "square"]
NORM = "Linf"
EPS_LIST = [0.5, 1, 2, 3, 4, 5, 6, 7, 8]  # /255 scale
```

### Adaptive Attack Settings
```python
ATTACK_TYPE = "adaptive_pgd"
NUM_STEPS = 100           # PGD iterations
STEP_SIZE = 2/255         # Step size per iteration
NUM_RESTARTS = 10         # Random restarts
LOSS = "CE"               # Cross-entropy loss
# Defense-aware components:
EOT_SAMPLES = 20          # For Randomized Smoothing
BPDA = True               # For Gradient Masking
```

---

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone repository
git clone https://github.com/<your-username>/vision-mamba-robustness.git
cd vision-mamba-robustness

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

### 2. Dataset Preparation

The Indonesian Traffic Sign dataset should be organized as:
```
data/dataset_rambu_lalu_lintas/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ batas_kecepatan_30/
â”‚   â”œâ”€â”€ batas_kecepatan_40/
â”‚   â”œâ”€â”€ ... (21 classes)
â”œâ”€â”€ valid/
â”‚   â””â”€â”€ ... (same structure)
â””â”€â”€ test/
    â””â”€â”€ ... (same structure)
```

### 3. Download Model Checkpoints

Place model checkpoints in the `models/` directory. Each defense method has its own subfolder.

### 4. Run Evaluation

```bash
# AutoAttack on baseline model
python src/evaluation/Autoattack_On_BaseModel.py

# Adaptive Attack on baseline model
python src/evaluation/Adapative_attack_on_base_Model.py

# AutoAttack on Adversarial Training model
python src/evaluation/Attack_on_AdversarialTrain.py
```

---

## ğŸ“Š Expected Outputs

Each evaluation script generates:

1. **CSV Report**: `{attack_type}_report_{timestamp}.csv`
   - Columns: epsilon, clean_accuracy, robust_accuracy, attack_success_rate

2. **Accuracy Plot**: `accuracy_vs_epsilon_{timestamp}.png`
   - X-axis: Epsilon (perturbation budget)
   - Y-axis: Accuracy (%)

3. **Attack Success Rate Plot**: `asr_vs_epsilon_{timestamp}.png`
   - Shows how attack effectiveness increases with epsilon

4. **Adversarial Examples Grid** (Adaptive Attack only):
   - Visual comparison of clean vs. adversarial images

---

## ğŸ“ˆ Key Results Summary

| Defense Method | Clean Acc. | Robust Acc. (Îµ=8/255) | Remarks |
|----------------|------------|----------------------|---------|
| Baseline | ~95% | ~0% | Highly vulnerable |
| Adversarial Training | ~88% | ~45% | **Most effective** |
| Randomized Smoothing | ~90% | ~15% | Partial improvement |
| Certified Robust | ~85% | ~10% | Formal guarantees but limited |
| Defensive Distillation | ~92% | ~5% | False robustness detected |
| Gradient Masking | ~93% | ~3% | False robustness detected |

> **Note**: Exact values may vary based on training configuration and random seeds.

---

## ğŸ”¬ Methodology (DSRM Mapping)

This repository supports Design Science Research Methodology:

| DSRM Phase | Artifact/Output |
|------------|-----------------|
| **Problem Identification** | Vision Mamba vulnerability analysis |
| **Design & Development** | Defense method implementations (`src/training/`) |
| **Demonstration** | Training scripts with checkpoints (`models/`) |
| **Evaluation** | Attack scripts with CSV/PNG outputs (`results/`) |
| **Communication** | Thesis document + this repository |

---

## ğŸ“š Dependencies

```
torch>=2.0.0
torchvision>=0.15.0
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.4.0
tqdm>=4.62.0
autoattack  # pip install git+https://github.com/fra31/auto-attack
mamba-ssm   # Vision Mamba core
causal-conv1d
```

---

## âš ï¸ Important Notes

1. **GPU Memory**: Evaluation requires at least 8GB GPU memory
2. **Attack Duration**: Full AutoAttack evaluation takes ~2-4 hours per model
3. **Reproducibility**: Set `torch.manual_seed(42)` for consistent results
4. **Path Configuration**: Update `BASE_DIR`, `DATA_ROOT` in each script to match your setup

---

## ğŸ“– References

1. Goodfellow, I. J., et al. (2014). "Explaining and Harnessing Adversarial Examples"
2. Madry, A., et al. (2018). "Towards Deep Learning Models Resistant to Adversarial Attacks"
3. Croce, F., & Hein, M. (2020). "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks"
4. Zhu, L., et al. (2024). "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model"
5. Cohen, J., et al. (2019). "Certified Adversarial Robustness via Randomized Smoothing"

---

## ğŸ“„ License

This research artifact is provided for academic and research purposes. Please cite the thesis if you use this code.

---

## ğŸ“§ Contact

For questions or collaboration inquiries:
- **Author**: Marthen Amelius Solang
- **Institution**: Institut Teknologi Bandung (ITB)
- **Program**: Master's in Informatics

---

*Last updated: December 2025*
